{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Reshape, Activation, Dropout\n",
    "from keras.layers import LSTM, Dense, Add, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04802181, 0.90796024, 1.1933948 , ..., 1.867591  , 0.4990241 ,\n",
       "        1.9825053 ],\n",
       "       [0.787118  , 0.24431148, 0.06212842, ..., 1.5899594 , 1.5548197 ,\n",
       "        2.0951674 ],\n",
       "       [1.1351358 , 0.643366  , 1.2675045 , ..., 0.44118398, 3.6098127 ,\n",
       "        0.21706353],\n",
       "       [2.510353  , 2.1102235 , 0.42487723, ..., 0.2930224 , 0.46952274,\n",
       "        0.3113997 ],\n",
       "       [1.4251724 , 0.42584297, 0.9633813 , ..., 1.9000303 , 1.1129313 ,\n",
       "        0.12448684]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = np.load('Files/img_vectors_sample.npy')\n",
    "image_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1913, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458752</td>\n",
       "      <td>What is this photo taken looking through?</td>\n",
       "      <td>458752000</td>\n",
       "      <td>(((tf.Tensor(-0.1294253, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458752</td>\n",
       "      <td>What position is this man playing?</td>\n",
       "      <td>458752001</td>\n",
       "      <td>(((tf.Tensor(-0.11989767, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458752</td>\n",
       "      <td>What color is the players shirt?</td>\n",
       "      <td>458752002</td>\n",
       "      <td>(((tf.Tensor(-0.085942656, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458752</td>\n",
       "      <td>Is this man a professional baseball player?</td>\n",
       "      <td>458752003</td>\n",
       "      <td>(((tf.Tensor(-0.11925976, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262146</td>\n",
       "      <td>What color is the snow?</td>\n",
       "      <td>262146000</td>\n",
       "      <td>(((tf.Tensor(-0.04078256, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                     question  question_id  \\\n",
       "0    458752    What is this photo taken looking through?    458752000   \n",
       "1    458752           What position is this man playing?    458752001   \n",
       "2    458752             What color is the players shirt?    458752002   \n",
       "3    458752  Is this man a professional baseball player?    458752003   \n",
       "4    262146                      What color is the snow?    262146000   \n",
       "\n",
       "                                                 vec  \n",
       "0  (((tf.Tensor(-0.1294253, shape=(), dtype=float...  \n",
       "1  (((tf.Tensor(-0.11989767, shape=(), dtype=floa...  \n",
       "2  (((tf.Tensor(-0.085942656, shape=(), dtype=flo...  \n",
       "3  (((tf.Tensor(-0.11925976, shape=(), dtype=floa...  \n",
       "4  (((tf.Tensor(-0.04078256, shape=(), dtype=floa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features = pickle.load(open(\"Files/bert_small.pkl\", \"rb\"))\n",
    "question_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (((tf.Tensor(-0.1294253, shape=(), dtype=float...\n",
       "1    (((tf.Tensor(-0.11989767, shape=(), dtype=floa...\n",
       "2    (((tf.Tensor(-0.085942656, shape=(), dtype=flo...\n",
       "3    (((tf.Tensor(-0.11925976, shape=(), dtype=floa...\n",
       "4    (((tf.Tensor(-0.04078256, shape=(), dtype=floa...\n",
       "Name: vec, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features['vec'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features['vec'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 34, 32, ..., 37, 26, 59])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = []\n",
    "for quest in question_features['question']:\n",
    "    lens.append(len(quest))\n",
    "question_length = np.array(lens)\n",
    "question_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9935,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_length.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 24,\n",
       " 29,\n",
       " 33,\n",
       " 35,\n",
       " 48,\n",
       " 60,\n",
       " 63,\n",
       " 70,\n",
       " 71,\n",
       " 76,\n",
       " 77,\n",
       " 80,\n",
       " 88,\n",
       " 91,\n",
       " 93,\n",
       " 108,\n",
       " 109,\n",
       " 112,\n",
       " 126,\n",
       " 137,\n",
       " 141,\n",
       " 143,\n",
       " 148,\n",
       " 153,\n",
       " 164,\n",
       " 193,\n",
       " 200,\n",
       " 246,\n",
       " 249,\n",
       " 259,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 311,\n",
       " 314,\n",
       " 320,\n",
       " 321,\n",
       " 325,\n",
       " 331,\n",
       " 367,\n",
       " 369,\n",
       " 381,\n",
       " 383,\n",
       " 388,\n",
       " 393,\n",
       " 403,\n",
       " 418,\n",
       " 430,\n",
       " 435,\n",
       " 437,\n",
       " 442,\n",
       " 449,\n",
       " 470,\n",
       " 507,\n",
       " 509,\n",
       " 513,\n",
       " 528,\n",
       " 530,\n",
       " 531,\n",
       " 539,\n",
       " 541,\n",
       " 561,\n",
       " 571,\n",
       " 574,\n",
       " 580,\n",
       " 583,\n",
       " 594,\n",
       " 596,\n",
       " 604,\n",
       " 611,\n",
       " 619,\n",
       " 624,\n",
       " 628,\n",
       " 633,\n",
       " 642,\n",
       " 649,\n",
       " 655,\n",
       " 658,\n",
       " 672,\n",
       " 680,\n",
       " 689,\n",
       " 713,\n",
       " 715,\n",
       " 721,\n",
       " 722,\n",
       " 734,\n",
       " 753,\n",
       " 761,\n",
       " 780,\n",
       " 789,\n",
       " 794,\n",
       " 796,\n",
       " 824,\n",
       " 827,\n",
       " 852,\n",
       " 881,\n",
       " 896,\n",
       " 901,\n",
       " 907,\n",
       " 908,\n",
       " 912,\n",
       " 924,\n",
       " 926,\n",
       " 933,\n",
       " 940,\n",
       " 954,\n",
       " 964,\n",
       " 981,\n",
       " 983,\n",
       " 995,\n",
       " 1005,\n",
       " 1013,\n",
       " 1024,\n",
       " 1035,\n",
       " 1058,\n",
       " 1071,\n",
       " 1083,\n",
       " 1089,\n",
       " 1098,\n",
       " 1101,\n",
       " 1106,\n",
       " 1107,\n",
       " 1110,\n",
       " 1121,\n",
       " 1138,\n",
       " 1154,\n",
       " 1165,\n",
       " 1167,\n",
       " 1182,\n",
       " 1199,\n",
       " 1203,\n",
       " 1215,\n",
       " 1223,\n",
       " 1231,\n",
       " 1263,\n",
       " 1270,\n",
       " 1281,\n",
       " 1294,\n",
       " 1305,\n",
       " 1306,\n",
       " 1307,\n",
       " 1310,\n",
       " 1314,\n",
       " 1329,\n",
       " 1331,\n",
       " 1354,\n",
       " 1359,\n",
       " 1365,\n",
       " 1374,\n",
       " 1380,\n",
       " 1385,\n",
       " 1389,\n",
       " 1391,\n",
       " 1396,\n",
       " 1400,\n",
       " 1402,\n",
       " 1406,\n",
       " 1407,\n",
       " 1430,\n",
       " 1452,\n",
       " 1454,\n",
       " 1471,\n",
       " 1487,\n",
       " 1495,\n",
       " 1496,\n",
       " 1500,\n",
       " 1504,\n",
       " 1506,\n",
       " 1509,\n",
       " 1514,\n",
       " 1517,\n",
       " 1521,\n",
       " 1525,\n",
       " 1535,\n",
       " 1547,\n",
       " 1557,\n",
       " 1561,\n",
       " 1568,\n",
       " 1578,\n",
       " 1579,\n",
       " 1585,\n",
       " 1588,\n",
       " 1610,\n",
       " 1621,\n",
       " 1624,\n",
       " 1636,\n",
       " 1638,\n",
       " 1644,\n",
       " 1669,\n",
       " 1673,\n",
       " 1680,\n",
       " 1696,\n",
       " 1711,\n",
       " 1719,\n",
       " 1736,\n",
       " 1761,\n",
       " 1763,\n",
       " 1770,\n",
       " 1773,\n",
       " 1776,\n",
       " 1780,\n",
       " 1785,\n",
       " 1789,\n",
       " 1791,\n",
       " 1803,\n",
       " 1810,\n",
       " 1812,\n",
       " 1814,\n",
       " 1821,\n",
       " 1836,\n",
       " 1876,\n",
       " 1887,\n",
       " 1894,\n",
       " 1901,\n",
       " 1905,\n",
       " 1906,\n",
       " 1910,\n",
       " 1911,\n",
       " 1914,\n",
       " 1923,\n",
       " 1941,\n",
       " 1942,\n",
       " 1965,\n",
       " 1993,\n",
       " 1998,\n",
       " 2023,\n",
       " 2055,\n",
       " 2065,\n",
       " 2071,\n",
       " 2082,\n",
       " 2088,\n",
       " 2113,\n",
       " 2134,\n",
       " 2147,\n",
       " 2149,\n",
       " 2183,\n",
       " 2210,\n",
       " 2216,\n",
       " 2231,\n",
       " 2257,\n",
       " 2275,\n",
       " 2277,\n",
       " 2278,\n",
       " 2279,\n",
       " 2280,\n",
       " 2282,\n",
       " 2295,\n",
       " 2336,\n",
       " 2341,\n",
       " 2348,\n",
       " 2371,\n",
       " 2373,\n",
       " 2376,\n",
       " 2388,\n",
       " 2399,\n",
       " 2401,\n",
       " 2410,\n",
       " 2414,\n",
       " 2428,\n",
       " 2443,\n",
       " 2447,\n",
       " 2465,\n",
       " 2469,\n",
       " 2495,\n",
       " 2497,\n",
       " 2530,\n",
       " 2535,\n",
       " 2542,\n",
       " 2543,\n",
       " 2544,\n",
       " 2554,\n",
       " 2559,\n",
       " 2562,\n",
       " 2566,\n",
       " 2569,\n",
       " 2574,\n",
       " 2582,\n",
       " 2584,\n",
       " 2590,\n",
       " 2605,\n",
       " 2607,\n",
       " 2617,\n",
       " 2618,\n",
       " 2622,\n",
       " 2623,\n",
       " 2643,\n",
       " 2663,\n",
       " 2686,\n",
       " 2692,\n",
       " 2696,\n",
       " 2702,\n",
       " 2731,\n",
       " 2741,\n",
       " 2751,\n",
       " 2753,\n",
       " 2754,\n",
       " 2757,\n",
       " 2769,\n",
       " 2773,\n",
       " 2775,\n",
       " 2781,\n",
       " 2841,\n",
       " 2842,\n",
       " 2848,\n",
       " 2859,\n",
       " 2885,\n",
       " 2891,\n",
       " 2901,\n",
       " 2906,\n",
       " 2930,\n",
       " 4375,\n",
       " 4376,\n",
       " 4409,\n",
       " 4440,\n",
       " 4461,\n",
       " 8746,\n",
       " 20089,\n",
       " 21825,\n",
       " 21894,\n",
       " 21914,\n",
       " 21925,\n",
       " 21944,\n",
       " 21963,\n",
       " 21982,\n",
       " 21990,\n",
       " 22153,\n",
       " 22179,\n",
       " 22193,\n",
       " 22197,\n",
       " 22221,\n",
       " 22222,\n",
       " 22267,\n",
       " 22280,\n",
       " 22308,\n",
       " 25141,\n",
       " 26226,\n",
       " 30584,\n",
       " 30618,\n",
       " 33176,\n",
       " 34932,\n",
       " 35007,\n",
       " 37185,\n",
       " 39287,\n",
       " 39370,\n",
       " 43696,\n",
       " 43772,\n",
       " 43779,\n",
       " 43892,\n",
       " 43935,\n",
       " 44046,\n",
       " 44116,\n",
       " 44146,\n",
       " 44159,\n",
       " 48046,\n",
       " 49356,\n",
       " 51503,\n",
       " 53930,\n",
       " 56771,\n",
       " 61143,\n",
       " 62851,\n",
       " 65715,\n",
       " 65736,\n",
       " 65834,\n",
       " 65904,\n",
       " 66002,\n",
       " 66013,\n",
       " 69928,\n",
       " 74252,\n",
       " 78651,\n",
       " 80584,\n",
       " 82997,\n",
       " 83101,\n",
       " 84682,\n",
       " 87512,\n",
       " 87517,\n",
       " 87524,\n",
       " 87553,\n",
       " 87632,\n",
       " 87661,\n",
       " 87725,\n",
       " 95158,\n",
       " 96066,\n",
       " 98719,\n",
       " 100412,\n",
       " 100559,\n",
       " 101430,\n",
       " 104816,\n",
       " 104843,\n",
       " 107715,\n",
       " 109147,\n",
       " 109155,\n",
       " 109276,\n",
       " 109323,\n",
       " 109398,\n",
       " 109408,\n",
       " 109552,\n",
       " 109621,\n",
       " 109699,\n",
       " 109985,\n",
       " 112496,\n",
       " 113512,\n",
       " 114352,\n",
       " 117938,\n",
       " 126650,\n",
       " 131010,\n",
       " 131073,\n",
       " 131074,\n",
       " 131083,\n",
       " 131086,\n",
       " 131092,\n",
       " 131100,\n",
       " 131112,\n",
       " 131117,\n",
       " 131125,\n",
       " 131126,\n",
       " 131127,\n",
       " 131132,\n",
       " 131159,\n",
       " 131171,\n",
       " 131173,\n",
       " 131189,\n",
       " 131196,\n",
       " 131207,\n",
       " 131214,\n",
       " 131224,\n",
       " 131244,\n",
       " 131276,\n",
       " 131278,\n",
       " 131298,\n",
       " 131299,\n",
       " 131311,\n",
       " 131314,\n",
       " 131322,\n",
       " 131329,\n",
       " 131338,\n",
       " 131341,\n",
       " 131350,\n",
       " 131351,\n",
       " 131363,\n",
       " 131372,\n",
       " 131373,\n",
       " 131375,\n",
       " 131387,\n",
       " 131399,\n",
       " 131414,\n",
       " 131418,\n",
       " 131426,\n",
       " 131433,\n",
       " 131448,\n",
       " 131449,\n",
       " 131464,\n",
       " 131466,\n",
       " 131469,\n",
       " 131484,\n",
       " 131485,\n",
       " 131486,\n",
       " 131497,\n",
       " 131508,\n",
       " 131510,\n",
       " 131521,\n",
       " 131523,\n",
       " 131563,\n",
       " 131564,\n",
       " 131578,\n",
       " 131588,\n",
       " 131594,\n",
       " 131612,\n",
       " 131620,\n",
       " 131665,\n",
       " 131673,\n",
       " 131677,\n",
       " 131695,\n",
       " 131702,\n",
       " 131720,\n",
       " 131734,\n",
       " 131741,\n",
       " 131746,\n",
       " 131763,\n",
       " 131779,\n",
       " 131783,\n",
       " 131815,\n",
       " 131832,\n",
       " 131839,\n",
       " 131857,\n",
       " 131864,\n",
       " 131878,\n",
       " 131893,\n",
       " 131901,\n",
       " 131908,\n",
       " 131910,\n",
       " 131917,\n",
       " 131936,\n",
       " 131951,\n",
       " 131960,\n",
       " 131966,\n",
       " 131975,\n",
       " 131978,\n",
       " 131999,\n",
       " 132001,\n",
       " 132014,\n",
       " 132018,\n",
       " 132076,\n",
       " 132080,\n",
       " 132093,\n",
       " 132098,\n",
       " 132105,\n",
       " 132113,\n",
       " 132119,\n",
       " 132122,\n",
       " 132136,\n",
       " 132138,\n",
       " 132140,\n",
       " 132146,\n",
       " 132164,\n",
       " 132169,\n",
       " 132187,\n",
       " 132195,\n",
       " 132211,\n",
       " 132216,\n",
       " 132248,\n",
       " 132257,\n",
       " 132261,\n",
       " 132264,\n",
       " 132289,\n",
       " 132293,\n",
       " 132296,\n",
       " 132297,\n",
       " 132298,\n",
       " 132302,\n",
       " 132305,\n",
       " 132309,\n",
       " 132329,\n",
       " 132330,\n",
       " 132384,\n",
       " 132385,\n",
       " 132393,\n",
       " 132404,\n",
       " 132411,\n",
       " 132419,\n",
       " 132429,\n",
       " 132453,\n",
       " 132469,\n",
       " 132475,\n",
       " 132484,\n",
       " 132493,\n",
       " 132494,\n",
       " 132496,\n",
       " 132499,\n",
       " 132514,\n",
       " 132515,\n",
       " 132516,\n",
       " 132519,\n",
       " 132520,\n",
       " 132522,\n",
       " 132527,\n",
       " 132528,\n",
       " 132530,\n",
       " 132532,\n",
       " 132548,\n",
       " 132551,\n",
       " 132563,\n",
       " 132564,\n",
       " 132570,\n",
       " 132573,\n",
       " 132575,\n",
       " 132590,\n",
       " 132616,\n",
       " 132620,\n",
       " 132625,\n",
       " 132645,\n",
       " 132653,\n",
       " 132655,\n",
       " 132668,\n",
       " 132669,\n",
       " 132697,\n",
       " 132709,\n",
       " 132724,\n",
       " 132749,\n",
       " 132757,\n",
       " 132759,\n",
       " 132767,\n",
       " 132777,\n",
       " 132788,\n",
       " 132792,\n",
       " 132794,\n",
       " 132797,\n",
       " 132815,\n",
       " 132837,\n",
       " 132840,\n",
       " 132846,\n",
       " 132849,\n",
       " 132856,\n",
       " 132873,\n",
       " 132877,\n",
       " 132887,\n",
       " 132901,\n",
       " 132907,\n",
       " 132912,\n",
       " 132934,\n",
       " 132943,\n",
       " 132953,\n",
       " 132958,\n",
       " 132963,\n",
       " 132971,\n",
       " 132972,\n",
       " 132990,\n",
       " 132992,\n",
       " 132996,\n",
       " 133003,\n",
       " 133012,\n",
       " 133029,\n",
       " 133062,\n",
       " 133109,\n",
       " 133112,\n",
       " 133113,\n",
       " 133114,\n",
       " 133118,\n",
       " 133136,\n",
       " 133144,\n",
       " 133150,\n",
       " 133151,\n",
       " 133165,\n",
       " 133166,\n",
       " 133174,\n",
       " 133182,\n",
       " 133193,\n",
       " 133199,\n",
       " 133207,\n",
       " 133226,\n",
       " 133228,\n",
       " 133233,\n",
       " 133246,\n",
       " 133256,\n",
       " 133260,\n",
       " 133272,\n",
       " 133277,\n",
       " 133293,\n",
       " 133294,\n",
       " 133297,\n",
       " 133307,\n",
       " 133313,\n",
       " 133314,\n",
       " 133330,\n",
       " 133368,\n",
       " 133383,\n",
       " 133402,\n",
       " 133409,\n",
       " 133425,\n",
       " 133427,\n",
       " 133435,\n",
       " 133452,\n",
       " 133455,\n",
       " 133461,\n",
       " 133466,\n",
       " 133481,\n",
       " 133485,\n",
       " 133489,\n",
       " 133491,\n",
       " 133495,\n",
       " 133504,\n",
       " 133507,\n",
       " 133509,\n",
       " 133539,\n",
       " 133548,\n",
       " 133553,\n",
       " 133564,\n",
       " 133575,\n",
       " 133593,\n",
       " 133633,\n",
       " 133640,\n",
       " 133649,\n",
       " 133653,\n",
       " 133659,\n",
       " 133671,\n",
       " 133687,\n",
       " 133696,\n",
       " 133721,\n",
       " 133726,\n",
       " 133729,\n",
       " 133730,\n",
       " 133738,\n",
       " 133740,\n",
       " 133765,\n",
       " 133787,\n",
       " 133790,\n",
       " 133830,\n",
       " 133834,\n",
       " 133836,\n",
       " 133838,\n",
       " 133844,\n",
       " 133849,\n",
       " 133878,\n",
       " 133882,\n",
       " 133884,\n",
       " 133904,\n",
       " 133907,\n",
       " 133908,\n",
       " 133911,\n",
       " 133936,\n",
       " 133989,\n",
       " 133993,\n",
       " 134778,\n",
       " 135331,\n",
       " 135396,\n",
       " 136184,\n",
       " 137044,\n",
       " 137917,\n",
       " 137930,\n",
       " 139104,\n",
       " 142297,\n",
       " 144083,\n",
       " 144087,\n",
       " 151974,\n",
       " 152973,\n",
       " 153030,\n",
       " 153038,\n",
       " 153122,\n",
       " 153127,\n",
       " 153396,\n",
       " 154506,\n",
       " 155378,\n",
       " 157124,\n",
       " 157152,\n",
       " 157189,\n",
       " 157204,\n",
       " 157218,\n",
       " 165858,\n",
       " 165926,\n",
       " 170234,\n",
       " 170272,\n",
       " 170294,\n",
       " 171104,\n",
       " 174604,\n",
       " 174676,\n",
       " 174963,\n",
       " 175016,\n",
       " 175046,\n",
       " 175071,\n",
       " 175087,\n",
       " 175111,\n",
       " 175128,\n",
       " 175179,\n",
       " 175184,\n",
       " 175209,\n",
       " 175237,\n",
       " 175249,\n",
       " 177898,\n",
       " 178956,\n",
       " 181565,\n",
       " 183400,\n",
       " 192052,\n",
       " 192926,\n",
       " 194668,\n",
       " 194670,\n",
       " 196662,\n",
       " 196687,\n",
       " 196776,\n",
       " 197000,\n",
       " 197056,\n",
       " 197067,\n",
       " 199027,\n",
       " 200781,\n",
       " 200800,\n",
       " 202522,\n",
       " 202530,\n",
       " 205158,\n",
       " 209573,\n",
       " 209590,\n",
       " 212640,\n",
       " 212997,\n",
       " 213862,\n",
       " 218507,\n",
       " 218556,\n",
       " 218588,\n",
       " 218594,\n",
       " 218605,\n",
       " 218646,\n",
       " 218647,\n",
       " 218648,\n",
       " 218673,\n",
       " 218700,\n",
       " 218764,\n",
       " 218839,\n",
       " 218841,\n",
       " 218845,\n",
       " 218861,\n",
       " 222602,\n",
       " 225212,\n",
       " 227839,\n",
       " 231337,\n",
       " 233954,\n",
       " 238821,\n",
       " 239872,\n",
       " 240303,\n",
       " 240422,\n",
       " 240567,\n",
       " 240631,\n",
       " 241270,\n",
       " 248254,\n",
       " 248778,\n",
       " 248834,\n",
       " 249662,\n",
       " 250416,\n",
       " 255936,\n",
       " 257512,\n",
       " 261892,\n",
       " 262145,\n",
       " 262158,\n",
       " 262170,\n",
       " 262171,\n",
       " 262179,\n",
       " 262183,\n",
       " 262186,\n",
       " 262190,\n",
       " 262200,\n",
       " 262203,\n",
       " 262206,\n",
       " 262220,\n",
       " 262259,\n",
       " 262260,\n",
       " 262272,\n",
       " 262282,\n",
       " 262284,\n",
       " 262298,\n",
       " 262306,\n",
       " 262307,\n",
       " 262328,\n",
       " 262334,\n",
       " 262335,\n",
       " 262358,\n",
       " 262368,\n",
       " 262388,\n",
       " 262392,\n",
       " 262398,\n",
       " 262413,\n",
       " 262414,\n",
       " 262441,\n",
       " 262453,\n",
       " 262462,\n",
       " 262464,\n",
       " 262476,\n",
       " 262491,\n",
       " 262494,\n",
       " 262507,\n",
       " 262518,\n",
       " 262520,\n",
       " 262528,\n",
       " 262537,\n",
       " 262540,\n",
       " 262543,\n",
       " 262544,\n",
       " 262548,\n",
       " 262549,\n",
       " 262551,\n",
       " 262553,\n",
       " 262560,\n",
       " 262578,\n",
       " 262587,\n",
       " 262598,\n",
       " 262602,\n",
       " 262618,\n",
       " 262622,\n",
       " 262661,\n",
       " 262669,\n",
       " 262682,\n",
       " 262687,\n",
       " 262689,\n",
       " 262690,\n",
       " 262691,\n",
       " 262703,\n",
       " 262704,\n",
       " 262706,\n",
       " 262709,\n",
       " 262714,\n",
       " 262717,\n",
       " 262723,\n",
       " 262726,\n",
       " 262746,\n",
       " 262747,\n",
       " 262751,\n",
       " 262769,\n",
       " 262776,\n",
       " 262785,\n",
       " 262844,\n",
       " 262847,\n",
       " 262850,\n",
       " 262860,\n",
       " 262861,\n",
       " 262868,\n",
       " 262883,\n",
       " 262892,\n",
       " 262896,\n",
       " 262900,\n",
       " 262908,\n",
       " 262916,\n",
       " 262931,\n",
       " 262951,\n",
       " 262953,\n",
       " 262961,\n",
       " 262966,\n",
       " 262975,\n",
       " 262978,\n",
       " 262979,\n",
       " 262990,\n",
       " 263005,\n",
       " 263007,\n",
       " 263030,\n",
       " 263041,\n",
       " 263042,\n",
       " 263046,\n",
       " 263083,\n",
       " 263093,\n",
       " 263097,\n",
       " 263100,\n",
       " 263110,\n",
       " 263111,\n",
       " 263134,\n",
       " 263137,\n",
       " 263146,\n",
       " 263188,\n",
       " 263195,\n",
       " 263203,\n",
       " 263207,\n",
       " 263211,\n",
       " 263228,\n",
       " 263260,\n",
       " 263263,\n",
       " 263264,\n",
       " 263269,\n",
       " 263270,\n",
       " 263273,\n",
       " 263274,\n",
       " 263275,\n",
       " 263277,\n",
       " 263301,\n",
       " 263310,\n",
       " 263319,\n",
       " 263327,\n",
       " 263332,\n",
       " 263357,\n",
       " 263376,\n",
       " 263380,\n",
       " 263382,\n",
       " 263387,\n",
       " 263399,\n",
       " 263404,\n",
       " 263405,\n",
       " 263406,\n",
       " 263417,\n",
       " 263419,\n",
       " 263433,\n",
       " 263439,\n",
       " 263445,\n",
       " 263452,\n",
       " 263453,\n",
       " 263455,\n",
       " 263481,\n",
       " 263502,\n",
       " 263511,\n",
       " 263515,\n",
       " 263573,\n",
       " 263575,\n",
       " 263581,\n",
       " 263603,\n",
       " 263608,\n",
       " 263617,\n",
       " 263619,\n",
       " 263622,\n",
       " 263638,\n",
       " 263649,\n",
       " 263676,\n",
       " 263684,\n",
       " 263698,\n",
       " 263709,\n",
       " 263713,\n",
       " 263726,\n",
       " 263733,\n",
       " 263734,\n",
       " 263743,\n",
       " 263758,\n",
       " 263761,\n",
       " 263763,\n",
       " 263766,\n",
       " 263778,\n",
       " 263783,\n",
       " 263809,\n",
       " 263822,\n",
       " 263825,\n",
       " 263844,\n",
       " 263858,\n",
       " 263872,\n",
       " 263874,\n",
       " 263875,\n",
       " 263877,\n",
       " 263882,\n",
       " 263895,\n",
       " 263900,\n",
       " 263923,\n",
       " 263967,\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids = []\n",
    "for x in question_features['image_id']:\n",
    "    if x not in image_ids:\n",
    "        image_ids.append(x)\n",
    "image_ids = np.array(image_ids) - 1\n",
    "sorted(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1913,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VQA_MODEL():\n",
    "    image_feature_size          = 4096\n",
    "    word_feature_size           = 300\n",
    "    number_of_LSTM              = 3\n",
    "    number_of_hidden_units_LSTM = 512\n",
    "    max_length_questions        = 30\n",
    "    number_of_dense_layers      = 3\n",
    "    number_of_hidden_units      = 1024\n",
    "    activation_function         = 'tanh'\n",
    "    dropout_pct                 = 0.5\n",
    "\n",
    "\n",
    "    # Image model\n",
    "    model_image = Sequential()\n",
    "    model_image.add(Reshape((image_feature_size,), input_shape=(image_feature_size,)))\n",
    "\n",
    "    # Language Model\n",
    "    model_language = Sequential()\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=True, input_shape=(max_length_questions, word_feature_size)))\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=True))\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=False))\n",
    "\n",
    "    # combined model\n",
    "    model = Sequential()\n",
    "    model.add(Concatenate([model_language, model_image], concat_axis=1))\n",
    "\n",
    "    for _ in xrange(number_of_dense_layers):\n",
    "        model.add(Dense(number_of_hidden_units, kernel_initializer='uniform'))\n",
    "        model.add(Activation(activation_function))\n",
    "        model.add(Dropout(dropout_pct))\n",
    "\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# def get_arguments():\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     # model\n",
    "#     parser.add_argument('-model'                  , type=str   , default='simple_mlp')\n",
    "#     parser.add_argument('-num_hidden_units_mlp'   , type=int   , default=1024)\n",
    "#     parser.add_argument('-num_hidden_units_lstm'  , type=int   , default=512)\n",
    "#     parser.add_argument('-num_hidden_layers_mlp'  , type=int   , default=3)\n",
    "#     parser.add_argument('-num_hidden_layers_lstm' , type=int   , default=1)\n",
    "#     parser.add_argument('-dropout'                , type=float , default=0.5)\n",
    "#     parser.add_argument('-activation_1'           , type=str   , default='tanh')\n",
    "#     parser.add_argument('-activation_2'           , type=str   , default='relu')\n",
    "\n",
    "#     # training\n",
    "#     parser.add_argument('-seed'                   , type=int   , default=1337)\n",
    "#     parser.add_argument('-optimizer'              , type=str   , default='rmsprop')\n",
    "#     parser.add_argument('-nb_epoch'               , type=int   , default=300)\n",
    "#     parser.add_argument('-nb_iter'                , type=int   , default=200000)\n",
    "#     parser.add_argument('-model_save_interval'    , type=int   , default=19)\n",
    "#     parser.add_argument('-batch_size'             , type=int   , default=128)\n",
    "\n",
    "    # language features\n",
    "#     parser.add_argument('-word_vector'            , type=str   , default='glove')\n",
    "#     parser.add_argument('-word_emb_dim'           , type=int   , default=300)\n",
    "#     parser.add_argument('-vocabulary_size'        , type=int   , default=12603)\n",
    "#     parser.add_argument('-max_ques_length'        , type=int   , default=26)\n",
    "#     parser.add_argument('-data_type'              , type=str   , default='TRAIN')\n",
    "\n",
    "    # image features\n",
    "#     parser.add_argument('-img_vec_dim'            , type=int   , default=2048)\n",
    "#     parser.add_argument('-img_features'           , type=str   , default='resnet')\n",
    "#     parser.add_argument('-img_normalize'          , type=int   , default=0)\n",
    "\n",
    "    # evaluations\n",
    "#     parser.add_argument('-nb_classes'             , type=int   , default=1000)\n",
    "#     parser.add_argument('-class_activation'       , type=str   , default='softmax')\n",
    "#     parser.add_argument('-loss'                   , type=str   , default='categorical_crossentropy')\n",
    "#     parser.add_argument('-save_folder'            , type=str   , default='')\n",
    "\n",
    "#     # data\n",
    "#     parser.add_argument('-ans_file'               , type=str   , default='data/val_all_answers_dict.json')\n",
    "#     parser.add_argument('-input_json'             , type=str   , default='data/data_prepro.json')\n",
    "#     parser.add_argument('-input_img_h5'           , type=str   , default='data/data_img.h5')\n",
    "#     parser.add_argument('-input_ques_h5'          , type=str   , default='data/data_prepro.h5')\n",
    "\n",
    "\n",
    "#     return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'simple_mlp'\n",
    "num_hidden_units_mlp = 1024\n",
    "num_hidden_units_lstm = 512\n",
    "num_hidden_layers_mlp = 3\n",
    "num_hidden_layers_lstm = 1\n",
    "dropout = 0.5\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'relu'\n",
    "seed = 1337\n",
    "optimizer = 'rmsprop'\n",
    "nb_epoch = 300\n",
    "nb_iter = 200000\n",
    "model_save_interval = 19\n",
    "batch_size = 128\n",
    "word_vector = 'glove'\n",
    "word_emb_dim = 300\n",
    "vocabulary_size = 12603\n",
    "max_ques_length = 26\n",
    "data_type = 'TRAIN'\n",
    "img_vec_dim = 2048\n",
    "img_features = 'resnet'\n",
    "img_normalize = 0\n",
    "nb_classes = 1000\n",
    "class_activation = 'softmax'\n",
    "loss = 'categorical_crossentropy'\n",
    "save_folder = ''\n",
    "# ans_file = 'data/val_all_answers_dict.json'\n",
    "# input_json = 'data/data_prepro.json'\n",
    "# input_img_h5 = 'data/data_img.h5'\n",
    "# input_ques_h5 ='data/data_prepro.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import h5py  as hf\n",
    "import json\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def get_train_data(args):\n",
    "\n",
    "#     dataset = {}\n",
    "    train_data = {}\n",
    "#     # load json file\n",
    "#     print('loading json file...')\n",
    "#     with open(args.input_json) as data_file:\n",
    "#         data = json.load(data_file)\n",
    "#     for key in data.keys():\n",
    "#         dataset[key] = data[key]\n",
    "\n",
    "    # load image feature\n",
    "    print('loading image feature...')\n",
    "#     with h5py.File(args.input_img_h5,'r') as hf:\n",
    "#         # -----0~82459------\n",
    "#         tem = hf.get('images_train')\n",
    "#         img_feature = np.array(tem)\n",
    "    img_feature = np.load('img_vectors_sample.npy')\n",
    "        \n",
    "    # load h5 file\n",
    "#     print('loading h5 file...')\n",
    "#     with h5py.File(args.input_ques_h5,'r') as hf:\n",
    "        # total number of training data is 215375\n",
    "        # question is (26, )\n",
    "#         tem = hf.get('ques_train')\n",
    "        train_data['question'] = question_features['vec'].numpy()\n",
    "        # max length is 23\n",
    "#         tem = hf.get('ques_length_train')\n",
    "        train_data['length_q'] = question_length\n",
    "        # total 82460 img\n",
    "        #-----1~82460-----\n",
    "#         tem = hf.get('img_pos_train')\n",
    "    # convert into 0~82459\n",
    "    \n",
    "        train_data['img_list'] = image_ids\n",
    "        # answer is 1~1000\n",
    "        tem = hf.get('answers')\n",
    "        train_data['answers'] = np.array(tem)-1\n",
    "\n",
    "    print('Normalizing image feature')\n",
    "    if img_norm:\n",
    "        tem = np.sqrt(np.sum(np.multiply(img_feature, img_feature)))\n",
    "        img_feature = np.divide(img_feature, np.tile(tem,(1,args.img_vec_dim)))\n",
    "\n",
    "    return img_feature, train_data\n",
    "\n",
    "def get_data_test(args):\n",
    "    dataset = {}\n",
    "    test_data = {}\n",
    "    # load json file\n",
    "    print('loading json file...')\n",
    "    with open(args.input_json) as data_file:\n",
    "        data = json.load(data_file)\n",
    "    for key in data.keys():\n",
    "        dataset[key] = data[key]\n",
    "\n",
    "    # load image feature\n",
    "    print('loading image feature...')\n",
    "    img_feature = np.load('img_vectors_sample.npy')\n",
    "    \n",
    "    # load h5 file\n",
    "    print('loading h5 file...')\n",
    "    with h5py.File(args.input_ques_h5,'r') as hf:\n",
    "        # total number of training data is 215375\n",
    "        # question is (26, )\n",
    "        tem = hf.get('ques_test')\n",
    "        test_data['question'] = np.array(tem)\n",
    "        # max length is 23\n",
    "        tem = hf.get('ques_length_test')\n",
    "        test_data['length_q'] = np.array(tem)\n",
    "        # total 82460 img\n",
    "        # -----1~82460-----\n",
    "        tem = hf.get('img_pos_test')\n",
    "        # convert into 0~82459\n",
    "        test_data['img_list'] = np.array(tem)-1\n",
    "        # quiestion id\n",
    "        tem = hf.get('question_id_test')\n",
    "        test_data['ques_id'] = np.array(tem)\n",
    "    # MC_answer_test\n",
    "    tem = hf.get('MC_ans_test')\n",
    "    test_data['MC_ans_test'] = np.array(tem)\n",
    "\n",
    "    print('Normalizing image feature')\n",
    "    if img_norm:\n",
    "        tem =  np.sqrt(np.sum(np.multiply(img_feature, img_feature)))\n",
    "        img_feature = np.divide(img_feature, np.tile(tem,(1,args.img_vec_dim)))\n",
    "\n",
    "\n",
    "    # make sure the ans_file is provided\n",
    "    nb_data_test = len(test_data[u'question'])\n",
    "    val_all_answers_dict = json.load(open(args.ans_file))\n",
    "    val_answers = np.zeros(nb_data_test, dtype=np.int32)\n",
    "\n",
    "    ans_to_ix = {v: k for k, v in dataset[u'ix_to_ans'].items()}\n",
    "    count_of_not_found = 0\n",
    "    for i in xrange(nb_data_test):\n",
    "        qid = test_data[u'ques_id'][i]\n",
    "        try : \n",
    "            val_ans_ix =int(ans_to_ix[most_common(val_all_answers_dict[str(qid)])]) -1\n",
    "        except KeyError:\n",
    "            count_of_not_found += 1\n",
    "            val_ans_ix = 480\n",
    "        val_answers[i] = val_ans_ix\n",
    "    print(\"Beware: \" + str(count_of_not_found) + \" number of val answers are not really correct\")\n",
    "\n",
    "    return img_feature, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "args = get_arguments()\n",
    "print(args)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "train_img_feature, train_data = get_train_data(args)\n",
    "test_img_feature,  test_data, val_answers = get_test_data(args)\n",
    "\n",
    "train_X = [train_data[u'question'], train_img_feature]\n",
    "train_Y = np_utils.to_categorical(train_data[u'answers'], args.nb_classes)\n",
    "\n",
    "test_X = [test_data[u'question'], test_img_feature]\n",
    "test_Y = np_utils.to_categorical(val_answers, args.nb_classes)\n",
    "\n",
    "\n",
    "model_name = importlib.import_module(\"models.\"+args.model)\n",
    "model = model_name.model(args)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=args.optimizer, metrics=['accuracy'])\n",
    "model.summary() # prints model layers with weights\n",
    "\n",
    "history = model.fit(train_X, train_Y, batch_size = args.batch_size, nb_epoch=args.nb_epoch, validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VQA_weights_file_name   = 'models/VQA/VQA_MODEL_WEIGHTS.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VQA_model(VQA_weights_file_name):\n",
    "    ''' Given the VQA model and its weights, compiles and returns the model '''\n",
    "\n",
    "    from models.VQA.VQA import VQA_MODEL\n",
    "    vqa_model = VQA_MODEL()\n",
    "    vqa_model.load_weights(VQA_weights_file_name)\n",
    "\n",
    "    vqa_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return vqa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_model = get_VQA_model(VQA_weights_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_model.predict([question_features, image_features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
