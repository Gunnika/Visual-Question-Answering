{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Reshape, Activation, Dropout\n",
    "from keras.layers import LSTM, Dense, Add, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04802181, 0.90796024, 1.1933948 , ..., 1.867591  , 0.4990241 ,\n",
       "        1.9825053 ],\n",
       "       [0.787118  , 0.24431148, 0.06212842, ..., 1.5899594 , 1.5548197 ,\n",
       "        2.0951674 ],\n",
       "       [1.1351358 , 0.643366  , 1.2675045 , ..., 0.44118398, 3.6098127 ,\n",
       "        0.21706353],\n",
       "       [2.510353  , 2.1102235 , 0.42487723, ..., 0.2930224 , 0.46952274,\n",
       "        0.3113997 ],\n",
       "       [1.4251724 , 0.42584297, 0.9633813 , ..., 1.9000303 , 1.1129313 ,\n",
       "        0.12448684]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features = np.load('Files/img_vectors_sample.npy')\n",
    "image_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1913, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>question</th>\n",
       "      <th>question_id</th>\n",
       "      <th>vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>458752</td>\n",
       "      <td>What is this photo taken looking through?</td>\n",
       "      <td>458752000</td>\n",
       "      <td>(((tf.Tensor(-0.1294253, shape=(), dtype=float...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>458752</td>\n",
       "      <td>What position is this man playing?</td>\n",
       "      <td>458752001</td>\n",
       "      <td>(((tf.Tensor(-0.11989767, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>458752</td>\n",
       "      <td>What color is the players shirt?</td>\n",
       "      <td>458752002</td>\n",
       "      <td>(((tf.Tensor(-0.085942656, shape=(), dtype=flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>458752</td>\n",
       "      <td>Is this man a professional baseball player?</td>\n",
       "      <td>458752003</td>\n",
       "      <td>(((tf.Tensor(-0.11925976, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262146</td>\n",
       "      <td>What color is the snow?</td>\n",
       "      <td>262146000</td>\n",
       "      <td>(((tf.Tensor(-0.04078256, shape=(), dtype=floa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                     question  question_id  \\\n",
       "0    458752    What is this photo taken looking through?    458752000   \n",
       "1    458752           What position is this man playing?    458752001   \n",
       "2    458752             What color is the players shirt?    458752002   \n",
       "3    458752  Is this man a professional baseball player?    458752003   \n",
       "4    262146                      What color is the snow?    262146000   \n",
       "\n",
       "                                                 vec  \n",
       "0  (((tf.Tensor(-0.1294253, shape=(), dtype=float...  \n",
       "1  (((tf.Tensor(-0.11989767, shape=(), dtype=floa...  \n",
       "2  (((tf.Tensor(-0.085942656, shape=(), dtype=flo...  \n",
       "3  (((tf.Tensor(-0.11925976, shape=(), dtype=floa...  \n",
       "4  (((tf.Tensor(-0.04078256, shape=(), dtype=floa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features = pickle.load(open(\"Files/bert_small.pkl\", \"rb\"))\n",
    "question_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (((tf.Tensor(-0.1294253, shape=(), dtype=float...\n",
       "1    (((tf.Tensor(-0.11989767, shape=(), dtype=floa...\n",
       "2    (((tf.Tensor(-0.085942656, shape=(), dtype=flo...\n",
       "3    (((tf.Tensor(-0.11925976, shape=(), dtype=floa...\n",
       "4    (((tf.Tensor(-0.04078256, shape=(), dtype=floa...\n",
       "Name: vec, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features['vec'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_features['vec'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 34, 32, ..., 37, 26, 59])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = []\n",
    "for quest in question_features['question']:\n",
    "    lens.append(len(quest))\n",
    "question_length = np.array(lens)\n",
    "question_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VQA_MODEL():\n",
    "    image_feature_size          = 4096\n",
    "    word_feature_size           = 300\n",
    "    number_of_LSTM              = 3\n",
    "    number_of_hidden_units_LSTM = 512\n",
    "    max_length_questions        = 30\n",
    "    number_of_dense_layers      = 3\n",
    "    number_of_hidden_units      = 1024\n",
    "    activation_function         = 'tanh'\n",
    "    dropout_pct                 = 0.5\n",
    "\n",
    "\n",
    "    # Image model\n",
    "    model_image = Sequential()\n",
    "    model_image.add(Reshape((image_feature_size,), input_shape=(image_feature_size,)))\n",
    "\n",
    "    # Language Model\n",
    "    model_language = Sequential()\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=True, input_shape=(max_length_questions, word_feature_size)))\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=True))\n",
    "    model_language.add(LSTM(number_of_hidden_units_LSTM, return_sequences=False))\n",
    "\n",
    "    # combined model\n",
    "    model = Sequential()\n",
    "    model.add(Concatenate([model_language, model_image], concat_axis=1))\n",
    "\n",
    "    for _ in xrange(number_of_dense_layers):\n",
    "        model.add(Dense(number_of_hidden_units, kernel_initializer='uniform'))\n",
    "        model.add(Activation(activation_function))\n",
    "        model.add(Dropout(dropout_pct))\n",
    "\n",
    "    model.add(Dense(1000))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "\n",
    "# def get_arguments():\n",
    "\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     # model\n",
    "#     parser.add_argument('-model'                  , type=str   , default='simple_mlp')\n",
    "#     parser.add_argument('-num_hidden_units_mlp'   , type=int   , default=1024)\n",
    "#     parser.add_argument('-num_hidden_units_lstm'  , type=int   , default=512)\n",
    "#     parser.add_argument('-num_hidden_layers_mlp'  , type=int   , default=3)\n",
    "#     parser.add_argument('-num_hidden_layers_lstm' , type=int   , default=1)\n",
    "#     parser.add_argument('-dropout'                , type=float , default=0.5)\n",
    "#     parser.add_argument('-activation_1'           , type=str   , default='tanh')\n",
    "#     parser.add_argument('-activation_2'           , type=str   , default='relu')\n",
    "\n",
    "#     # training\n",
    "#     parser.add_argument('-seed'                   , type=int   , default=1337)\n",
    "#     parser.add_argument('-optimizer'              , type=str   , default='rmsprop')\n",
    "#     parser.add_argument('-nb_epoch'               , type=int   , default=300)\n",
    "#     parser.add_argument('-nb_iter'                , type=int   , default=200000)\n",
    "#     parser.add_argument('-model_save_interval'    , type=int   , default=19)\n",
    "#     parser.add_argument('-batch_size'             , type=int   , default=128)\n",
    "\n",
    "    # language features\n",
    "#     parser.add_argument('-word_vector'            , type=str   , default='glove')\n",
    "#     parser.add_argument('-word_emb_dim'           , type=int   , default=300)\n",
    "#     parser.add_argument('-vocabulary_size'        , type=int   , default=12603)\n",
    "#     parser.add_argument('-max_ques_length'        , type=int   , default=26)\n",
    "#     parser.add_argument('-data_type'              , type=str   , default='TRAIN')\n",
    "\n",
    "    # image features\n",
    "#     parser.add_argument('-img_vec_dim'            , type=int   , default=2048)\n",
    "#     parser.add_argument('-img_features'           , type=str   , default='resnet')\n",
    "#     parser.add_argument('-img_normalize'          , type=int   , default=0)\n",
    "\n",
    "    # evaluations\n",
    "#     parser.add_argument('-nb_classes'             , type=int   , default=1000)\n",
    "#     parser.add_argument('-class_activation'       , type=str   , default='softmax')\n",
    "#     parser.add_argument('-loss'                   , type=str   , default='categorical_crossentropy')\n",
    "#     parser.add_argument('-save_folder'            , type=str   , default='')\n",
    "\n",
    "#     # data\n",
    "#     parser.add_argument('-ans_file'               , type=str   , default='data/val_all_answers_dict.json')\n",
    "#     parser.add_argument('-input_json'             , type=str   , default='data/data_prepro.json')\n",
    "#     parser.add_argument('-input_img_h5'           , type=str   , default='data/data_img.h5')\n",
    "#     parser.add_argument('-input_ques_h5'          , type=str   , default='data/data_prepro.h5')\n",
    "\n",
    "\n",
    "#     return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'simple_mlp'\n",
    "num_hidden_units_mlp = 1024\n",
    "num_hidden_units_lstm = 512\n",
    "num_hidden_layers_mlp = 3\n",
    "num_hidden_layers_lstm = 1\n",
    "dropout = 0.5\n",
    "activation_1 = 'tanh'\n",
    "activation_2 = 'relu'\n",
    "seed = 1337\n",
    "optimizer = rmsprop\n",
    "nb_epoch = 300\n",
    "nb_iter = 200000\n",
    "model_save_interval = 19\n",
    "batch_size = 128\n",
    "word_vector = 'glove'\n",
    "word_emb_dim = 300\n",
    "vocabulary_size = 12603\n",
    "max_ques_length = 26\n",
    "data_type = 'TRAIN'\n",
    "img_vec_dim = 2048\n",
    "img_features = 'resnet'\n",
    "img_normalize = 0\n",
    "nb_classes = 1000\n",
    "class_activation = 'softmax'\n",
    "loss = 'categorical_crossentropy'\n",
    "save_folder = ''\n",
    "# ans_file = 'data/val_all_answers_dict.json'\n",
    "# input_json = 'data/data_prepro.json'\n",
    "# input_img_h5 = 'data/data_img.h5'\n",
    "# input_ques_h5 ='data/data_prepro.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import h5py  as hf\n",
    "import json\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def get_train_data(args):\n",
    "\n",
    "#     dataset = {}\n",
    "    train_data = {}\n",
    "#     # load json file\n",
    "#     print('loading json file...')\n",
    "#     with open(args.input_json) as data_file:\n",
    "#         data = json.load(data_file)\n",
    "#     for key in data.keys():\n",
    "#         dataset[key] = data[key]\n",
    "\n",
    "    # load image feature\n",
    "    print('loading image feature...')\n",
    "#     with h5py.File(args.input_img_h5,'r') as hf:\n",
    "#         # -----0~82459------\n",
    "#         tem = hf.get('images_train')\n",
    "#         img_feature = np.array(tem)\n",
    "    img_feature = np.load('img_vectors_sample.npy')\n",
    "        \n",
    "    # load h5 file\n",
    "#     print('loading h5 file...')\n",
    "#     with h5py.File(args.input_ques_h5,'r') as hf:\n",
    "        # total number of training data is 215375\n",
    "        # question is (26, )\n",
    "#         tem = hf.get('ques_train')\n",
    "        train_data['question'] = question_features['vec'].numpy()\n",
    "        # max length is 23\n",
    "#         tem = hf.get('ques_length_train')\n",
    "        train_data['length_q'] = question_length\n",
    "        # total 82460 img\n",
    "        #-----1~82460-----\n",
    "#         tem = hf.get('img_pos_train')\n",
    "    # convert into 0~82459\n",
    "        train_data['img_list'] = np.array(tem)-1\n",
    "        # answer is 1~1000\n",
    "        tem = hf.get('answers')\n",
    "        train_data['answers'] = np.array(tem)-1\n",
    "\n",
    "    print('Normalizing image feature')\n",
    "    if img_norm:\n",
    "        tem = np.sqrt(np.sum(np.multiply(img_feature, img_feature)))\n",
    "        img_feature = np.divide(img_feature, np.tile(tem,(1,args.img_vec_dim)))\n",
    "\n",
    "    return img_feature, train_data\n",
    "\n",
    "def get_data_test(args):\n",
    "    dataset = {}\n",
    "    test_data = {}\n",
    "    # load json file\n",
    "    print('loading json file...')\n",
    "    with open(args.input_json) as data_file:\n",
    "        data = json.load(data_file)\n",
    "    for key in data.keys():\n",
    "        dataset[key] = data[key]\n",
    "\n",
    "    # load image feature\n",
    "    print('loading image feature...')\n",
    "    img_feature = np.load('img_vectors_sample.npy')\n",
    "    \n",
    "    # load h5 file\n",
    "    print('loading h5 file...')\n",
    "    with h5py.File(args.input_ques_h5,'r') as hf:\n",
    "        # total number of training data is 215375\n",
    "        # question is (26, )\n",
    "        tem = hf.get('ques_test')\n",
    "        test_data['question'] = np.array(tem)\n",
    "        # max length is 23\n",
    "        tem = hf.get('ques_length_test')\n",
    "        test_data['length_q'] = np.array(tem)\n",
    "        # total 82460 img\n",
    "        # -----1~82460-----\n",
    "        tem = hf.get('img_pos_test')\n",
    "        # convert into 0~82459\n",
    "        test_data['img_list'] = np.array(tem)-1\n",
    "        # quiestion id\n",
    "        tem = hf.get('question_id_test')\n",
    "        test_data['ques_id'] = np.array(tem)\n",
    "    # MC_answer_test\n",
    "    tem = hf.get('MC_ans_test')\n",
    "    test_data['MC_ans_test'] = np.array(tem)\n",
    "\n",
    "#     print('Normalizing image feature')\n",
    "#     if img_norm:\n",
    "#         tem =  np.sqrt(np.sum(np.multiply(img_feature, img_feature)))\n",
    "#         img_feature = np.divide(img_feature, np.tile(tem,(1,args.img_vec_dim)))\n",
    "\n",
    "\n",
    "    # make sure the ans_file is provided\n",
    "    nb_data_test = len(test_data[u'question'])\n",
    "    val_all_answers_dict = json.load(open(args.ans_file))\n",
    "    val_answers = np.zeros(nb_data_test, dtype=np.int32)\n",
    "\n",
    "    ans_to_ix = {v: k for k, v in dataset[u'ix_to_ans'].items()}\n",
    "    count_of_not_found = 0\n",
    "    for i in xrange(nb_data_test):\n",
    "        qid = test_data[u'ques_id'][i]\n",
    "        try : \n",
    "            val_ans_ix =int(ans_to_ix[most_common(val_all_answers_dict[str(qid)])]) -1\n",
    "        except KeyError:\n",
    "            count_of_not_found += 1\n",
    "            val_ans_ix = 480\n",
    "        val_answers[i] = val_ans_ix\n",
    "    print(\"Beware: \" + str(count_of_not_found) + \" number of val answers are not really correct\")\n",
    "\n",
    "    return img_feature, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-model MODEL]\n",
      "                             [-num_hidden_units_mlp NUM_HIDDEN_UNITS_MLP]\n",
      "                             [-num_hidden_units_lstm NUM_HIDDEN_UNITS_LSTM]\n",
      "                             [-num_hidden_layers_mlp NUM_HIDDEN_LAYERS_MLP]\n",
      "                             [-num_hidden_layers_lstm NUM_HIDDEN_LAYERS_LSTM]\n",
      "                             [-dropout DROPOUT] [-activation_1 ACTIVATION_1]\n",
      "                             [-activation_2 ACTIVATION_2] [-seed SEED]\n",
      "                             [-optimizer OPTIMIZER] [-nb_epoch NB_EPOCH]\n",
      "                             [-nb_iter NB_ITER]\n",
      "                             [-model_save_interval MODEL_SAVE_INTERVAL]\n",
      "                             [-batch_size BATCH_SIZE]\n",
      "                             [-word_vector WORD_VECTOR]\n",
      "                             [-word_emb_dim WORD_EMB_DIM]\n",
      "                             [-vocabulary_size VOCABULARY_SIZE]\n",
      "                             [-max_ques_length MAX_QUES_LENGTH]\n",
      "                             [-data_type DATA_TYPE] [-img_vec_dim IMG_VEC_DIM]\n",
      "                             [-img_features IMG_FEATURES]\n",
      "                             [-img_normalize IMG_NORMALIZE]\n",
      "                             [-nb_classes NB_CLASSES]\n",
      "                             [-class_activation CLASS_ACTIVATION] [-loss LOSS]\n",
      "                             [-save_folder SAVE_FOLDER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/1000/jupyter/kernel-0560ece0-5b4a-4e16-ad7d-a992f0e1d020.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "args = get_arguments()\n",
    "print(args)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "train_img_feature, train_data = get_train_data(args)\n",
    "test_img_feature,  test_data, val_answers = get_test_data(args)\n",
    "\n",
    "train_X = [train_data[u'question'], train_img_feature]\n",
    "train_Y = np_utils.to_categorical(train_data[u'answers'], args.nb_classes)\n",
    "\n",
    "test_X = [test_data[u'question'], test_img_feature]\n",
    "test_Y = np_utils.to_categorical(val_answers, args.nb_classes)\n",
    "\n",
    "\n",
    "model_name = importlib.import_module(\"models.\"+args.model)\n",
    "model = model_name.model(args)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=args.optimizer, metrics=['accuracy'])\n",
    "model.summary() # prints model layers with weights\n",
    "\n",
    "history = model.fit(train_X, train_Y, batch_size = args.batch_size, nb_epoch=args.nb_epoch, validation_data=(test_X, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VQA_weights_file_name   = 'models/VQA/VQA_MODEL_WEIGHTS.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_VQA_model(VQA_weights_file_name):\n",
    "    ''' Given the VQA model and its weights, compiles and returns the model '''\n",
    "\n",
    "    from models.VQA.VQA import VQA_MODEL\n",
    "    vqa_model = VQA_MODEL()\n",
    "    vqa_model.load_weights(VQA_weights_file_name)\n",
    "\n",
    "    vqa_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    return vqa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_model = get_VQA_model(VQA_weights_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqa_model.predict([question_features, image_features])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
